{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f28e466-e170-48a2-8311-5faed78d9165",
   "metadata": {},
   "source": [
    "# Assess Latency\n",
    "Measure the different sources of latency using a single- and multi-site implementation of Colmena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db65c851-df0c-4e28-951d-7e0d72cc177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1058aa01-62d8-4878-88d0-9c37ad7c506e",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0750fa51-58b0-4ded-a4a2-b763e5336a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcx = Path('prod-runs/8KNL-8V100-funcx/')\n",
    "parsl_redis = Path('prod-runs/8KNL-8V100-parsl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029775ed-4edf-489a-84b0-de5ee44a1ddb",
   "metadata": {},
   "source": [
    "## Assess \"Reaction Time\" between Result Available and Processed\n",
    "We look at the time between when a result completes on the worker, it is received by the task server, and processed by the thinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c3a6c0-2a6c-4a86-b3d4-f38caa7be434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reaction_times(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Get the reaction times for a certain run\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the run\n",
    "    Returns:\n",
    "        Many different analyses for each type of tasks. These include\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load in all of the tasks\n",
    "    tasks = pd.read_csv(path / 'processed-results' / 'all-tasks.csv')\n",
    "    tasks['run'] = path.name\n",
    "    \n",
    "    # Load compute the total proxy resolution time for inputs\n",
    "    def _get_resolve_time(x):\n",
    "        x = eval(x)\n",
    "        return sum(i['resolve']['avg_time_ms'] * i['resolve']['calls'] for i in x.values() if 'resolve' in i) / 1000\n",
    "    tasks['time_input_resolution'] = tasks['proxy_timing'].apply(_get_resolve_time)\n",
    "    \n",
    "    # Compute the time compute finished\n",
    "    tasks['time_compute_done'] = tasks['time_compute_started'] + tasks['time_deserialize_inputs'] + tasks['time_async_resolve_proxies'] + tasks['time_running']\n",
    "    \n",
    "    # Compute the difference between the completion time and when it was received by the thinker\n",
    "    tasks['latency_result_sending'] = tasks['time_result_received'] - tasks['time_compute_done']\n",
    "    \n",
    "    # Compute the time until the result was placed in the queue \n",
    "    tasks['latency_to_task_server'] = tasks['time_result_sent'] - tasks['time_compute_done']\n",
    "    \n",
    "    # How much of this time was communicating the result via FuncX/Parsl\n",
    "    tasks['latency_workflow'] = tasks['latency_result_sending'] - tasks['time_serialize_results']\n",
    "    \n",
    "    # Get the set time\n",
    "    def _get_resolve_time(x):\n",
    "        x = eval(x)\n",
    "        return sum(i['set']['avg_time_ms'] * i['set']['calls'] for i in x.values() if 'set' in i) / 1000\n",
    "    tasks['time_write_result_proxy'] = tasks['proxy_timing'].apply(_get_resolve_time)\n",
    "    \n",
    "    # Get the time waiting for the result to show up\n",
    "    def _get_resolve(x):\n",
    "        x = eval(x)\n",
    "        if 'proxy_stats' not in x:\n",
    "            return \n",
    "        assert 'resolve' in x['proxy_stats'], list(x['proxy_stats'].keys())\n",
    "        return x['proxy_stats']['resolve']['avg_time_ms'] / 1000\n",
    "    tasks['latency_data'] = tasks['task_info'].apply(_get_resolve)\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84b0212-8046-456b-abb3-6ba373aa4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (funcx / 'duplicates.json').open() as fp:\n",
    "    funcx_tasks = pd.concat([get_reaction_times(Path(x)) for x in json.load(fp)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdaf94a6-2f97-463c-80b5-ff164a68f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (parsl_redis / 'duplicates.json').open() as fp:\n",
    "    parsl_tasks = pd.concat([get_reaction_times(Path(x)) for x in json.load(fp)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb93bced-a000-4cc5-82b0-9288b890156a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007818896031684903"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsl_tasks.query('task_type==\"inference\"')[['time_deserialize_inputs', 'time_serialize_results']].sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146eb94b-52fb-4ecd-a19c-d683c1208dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3244.000000\n",
       "mean        0.273118\n",
       "std         0.170877\n",
       "min         0.122864\n",
       "25%         0.161041\n",
       "50%         0.181668\n",
       "75%         0.409820\n",
       "max         3.188594\n",
       "Name: time_serialize_results, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcx_tasks.query('task_type==\"inference\"')['time_serialize_results'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a776d651-6d3f-49bf-8844-086e97d811d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2731180090874057"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcx_tasks.query('task_type==\"inference\"')[['time_serialize_results']].sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734a224-f0cd-46d2-96d8-19be19dc0def",
   "metadata": {},
   "source": [
    "Compute the time between results completing and being received by the thinker. This measure conflates a few things: time to send notification and time the result is sitting in a processing backlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed833e2-de99-4643-b305-f3a323c1c975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3x/lib/python3.7/site-packages/IPython/core/events.py:89: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x162 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 2.25), sharex=True)\n",
    "\n",
    "min_ = np.log10(max(funcx_tasks['latency_to_task_server'].min(), 1e-2))\n",
    "max_ = np.log10(funcx_tasks['latency_result_sending'].max())\n",
    "bins = np.logspace(min_ - 0.1, max_ + 0.1, 64)\n",
    "\n",
    "for task_type, group in funcx_tasks.groupby('task_type'):\n",
    "    ax.hist(group['latency_result_sending'] , bins=bins, label=task_type)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('Compute Done $\\\\rightarrow$ Thinker (s)')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddccddbf-c004-488f-bb14-b849ae75b57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inference</th>\n",
       "      <td>3244.0</td>\n",
       "      <td>2.240193</td>\n",
       "      <td>7.048496</td>\n",
       "      <td>0.071938</td>\n",
       "      <td>0.172379</td>\n",
       "      <td>0.713741</td>\n",
       "      <td>2.799821</td>\n",
       "      <td>4.360759</td>\n",
       "      <td>95.287084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.074018</td>\n",
       "      <td>0.798690</td>\n",
       "      <td>-0.029736</td>\n",
       "      <td>0.014030</td>\n",
       "      <td>0.035901</td>\n",
       "      <td>0.064686</td>\n",
       "      <td>0.130715</td>\n",
       "      <td>30.998672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>243.0</td>\n",
       "      <td>0.535357</td>\n",
       "      <td>0.646727</td>\n",
       "      <td>-0.053026</td>\n",
       "      <td>0.243387</td>\n",
       "      <td>0.443596</td>\n",
       "      <td>0.546681</td>\n",
       "      <td>1.998777</td>\n",
       "      <td>4.701118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean       std       min       25%       50%  \\\n",
       "task_type                                                              \n",
       "inference   3244.0  2.240193  7.048496  0.071938  0.172379  0.713741   \n",
       "simulation  2000.0  0.074018  0.798690 -0.029736  0.014030  0.035901   \n",
       "training     243.0  0.535357  0.646727 -0.053026  0.243387  0.443596   \n",
       "\n",
       "                 75%       95%        max  \n",
       "task_type                                  \n",
       "inference   2.799821  4.360759  95.287084  \n",
       "simulation  0.064686  0.130715  30.998672  \n",
       "training    0.546681  1.998777   4.701118  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcx_tasks.groupby('task_type')['latency_result_sending'].describe(percentiles=[0.25,0.50,0.75,0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d05784-734d-4cb1-8516-95cd406cb73e",
   "metadata": {},
   "source": [
    "See the time between result completing and being acknolwedged by the task server, which removes any factor dealing with processing backlog on the thinker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a443a5ee-a224-4ae8-a615-f2e289fd7db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Compute Done $\\\\rightarrow$ Thinker (s)')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x162 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 2.25), sharex=True)\n",
    "\n",
    "min_ = np.log10(max(funcx_tasks['latency_workflow'].min(), 1e-2))\n",
    "max_ = np.log10(funcx_tasks['latency_result_sending'].max())\n",
    "bins = np.logspace(min_ - 0.1, max_ + 0.1, 64)\n",
    "\n",
    "for task_type, group in funcx_tasks.groupby('task_type'):\n",
    "    ax.hist(group['latency_to_task_server'] , bins=bins, label=task_type)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('Compute Done $\\\\rightarrow$ Thinker (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29db8a95-ba0e-4253-9a83-11cde1b6b01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inference</th>\n",
       "      <td>3244.0</td>\n",
       "      <td>0.237588</td>\n",
       "      <td>0.176197</td>\n",
       "      <td>0.060810</td>\n",
       "      <td>0.118962</td>\n",
       "      <td>0.148002</td>\n",
       "      <td>0.370081</td>\n",
       "      <td>3.151134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.067718</td>\n",
       "      <td>0.792638</td>\n",
       "      <td>-0.031114</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.061839</td>\n",
       "      <td>30.997886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>243.0</td>\n",
       "      <td>0.377672</td>\n",
       "      <td>0.218058</td>\n",
       "      <td>-0.053857</td>\n",
       "      <td>0.234297</td>\n",
       "      <td>0.299775</td>\n",
       "      <td>0.519043</td>\n",
       "      <td>1.510511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean       std       min       25%       50%  \\\n",
       "task_type                                                              \n",
       "inference   3244.0  0.237588  0.176197  0.060810  0.118962  0.148002   \n",
       "simulation  2000.0  0.067718  0.792638 -0.031114  0.012783  0.034268   \n",
       "training     243.0  0.377672  0.218058 -0.053857  0.234297  0.299775   \n",
       "\n",
       "                 75%        max  \n",
       "task_type                        \n",
       "inference   0.370081   3.151134  \n",
       "simulation  0.061839  30.997886  \n",
       "training    0.519043   1.510511  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcx_tasks.groupby('task_type')['latency_to_task_server'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b23854-2168-4023-939a-0987e43e0d81",
   "metadata": {},
   "source": [
    "See how much funcX has to do with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012d4bd-85ce-45dd-b627-71ecbaed5ed0",
   "metadata": {},
   "source": [
    "See how long we're waiting for the data to transfer. Th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e107419-fc07-4123-a53e-23ecad07ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3x/lib/python3.7/site-packages/IPython/core/pylabtools.py:137: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x162 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 2.25), sharex=True)\n",
    "\n",
    "min_ = np.log10(max(funcx_tasks['latency_data'].min(), 1e-2))\n",
    "max_ = np.log10(funcx_tasks['latency_data'].max())\n",
    "bins = np.logspace(min_ - 0.1, max_ + 0.1, 64)\n",
    "\n",
    "for task_type, group in funcx_tasks.groupby('task_type'):\n",
    "    ax.hist(group['latency_data'] , bins=bins, label=task_type)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('Compute Done $\\\\rightarrow$ Thinker (s)')\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/reaction-time-latency.png', dpi=320)\n",
    "fig.savefig('figures/reaction-time-latency.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe443fac-3207-4a16-afc3-76df140e67fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inference</th>\n",
       "      <td>1552.0</td>\n",
       "      <td>2.737774</td>\n",
       "      <td>2.747196</td>\n",
       "      <td>0.192097</td>\n",
       "      <td>1.366231</td>\n",
       "      <td>3.389624</td>\n",
       "      <td>3.673629</td>\n",
       "      <td>94.460706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.457035</td>\n",
       "      <td>0.046018</td>\n",
       "      <td>0.093567</td>\n",
       "      <td>0.106206</td>\n",
       "      <td>0.121327</td>\n",
       "      <td>14.264698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>115.0</td>\n",
       "      <td>3.777915</td>\n",
       "      <td>0.950902</td>\n",
       "      <td>0.265395</td>\n",
       "      <td>3.408722</td>\n",
       "      <td>3.701003</td>\n",
       "      <td>4.436832</td>\n",
       "      <td>7.617164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean       std       min       25%       50%  \\\n",
       "task_type                                                              \n",
       "inference   1552.0  2.737774  2.747196  0.192097  1.366231  3.389624   \n",
       "simulation  1000.0  0.134800  0.457035  0.046018  0.093567  0.106206   \n",
       "training     115.0  3.777915  0.950902  0.265395  3.408722  3.701003   \n",
       "\n",
       "                 75%        max  \n",
       "task_type                        \n",
       "inference   3.673629  94.460706  \n",
       "simulation  0.121327  14.264698  \n",
       "training    4.436832   7.617164  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcx_tasks.groupby('task_type')['latency_data'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af664968-95a2-46b8-a51f-ac0f58596e5b",
   "metadata": {},
   "source": [
    "Compile the two into a single figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91733ccd-4825-485e-8259-828f65cbe1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x136.8 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(3.5, 1.9), sharex=True, sharey=False)\n",
    "\n",
    "# Get the bins for the histogram\n",
    "min_ = -2.5\n",
    "max_ = np.log10(funcx_tasks['latency_data'].max())\n",
    "bins = np.logspace(min_ - 0.1, max_ + 0.1, 50)\n",
    "\n",
    "# Plot the data\n",
    "colors = {\n",
    "    'inference': 'deepskyblue',\n",
    "    'simulation': 'goldenrod',\n",
    "    'training': 'maroon'\n",
    "}\n",
    "for task_type, group in funcx_tasks.groupby('task_type'):\n",
    "    axs[0].hist(group['latency_to_task_server'], bins=bins, label=task_type,\n",
    "                edgecolor='k', facecolor=colors[task_type])\n",
    "    axs[1].hist(group['latency_data'], bins=bins, label=task_type,\n",
    "                edgecolor='k', facecolor=colors[task_type])\n",
    "\n",
    "# Label the axes\n",
    "for ax in axs:\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel('Frequency')\n",
    "axs[1].set_xlabel('Latency (s)')\n",
    "\n",
    "# Label the plots\n",
    "axs[0].text(0.01, 0.99, 'Notification', ha='left', va='top', fontsize=9,\n",
    "           transform=axs[0].transAxes)\n",
    "axs[1].text(0.01, 0.99, 'Access', ha='left', va='top', fontsize=9,\n",
    "           transform=axs[1].transAxes)\n",
    "\n",
    "axs[0].legend(fontsize=7, ncol=1)\n",
    "\n",
    "fig.tight_layout(h_pad=0.1)\n",
    "fig.savefig('figures/latency-analysis_reaction-time.png', dpi=320)\n",
    "fig.savefig('figures/latency-analysis_reaction-time.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f85b734-c690-4f53-a817-0bb03772b791",
   "metadata": {},
   "source": [
    "We see latencies never above 10s for either of the types of latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc7e77-b146-4141-bb02-d2fa842f110e",
   "metadata": {},
   "source": [
    "Repeat the analysis with Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528538a6-3541-45fd-af8e-d96707df493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(3.5, 2.75), sharex=True, sharey=False)\n",
    "\n",
    "# Get the bins for the histogram\n",
    "min_ = -3.5\n",
    "max_ = np.log10(parsl_tasks['latency_data'].max())\n",
    "bins = np.logspace(min_ - 0.1, max_ + 0.1, 64)\n",
    "\n",
    "# Plot the data\n",
    "for task_type, group in parsl_tasks.groupby('task_type'):\n",
    "    axs[0].hist(group['latency_to_task_server'], bins=bins, label=task_type, edgecolor='k')\n",
    "    axs[1].hist(group['latency_data'], bins=bins, label=task_type, edgecolor='k')\n",
    "\n",
    "# Label the axes\n",
    "for ax in axs:\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel('Frequency')\n",
    "axs[1].set_xlabel('Latency (s)')\n",
    "\n",
    "# Label the plots\n",
    "axs[0].set_title('Notification', loc='left', fontsize=9)\n",
    "axs[1].set_title('Access', loc='left', fontsize=9)\n",
    "\n",
    "axs[1].legend(fontsize=7)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/latency-analysis_reaction-time-parsl.png', dpi=320)\n",
    "fig.savefig('figures/latency-analysis_reaction-time-parsl.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574e01f-1b8e-4ed5-950e-9f492fe3a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsl_tasks.groupby('task_type')['latency_data'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6344c9e-c67e-42ed-931e-f823e21aaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsl_tasks.groupby('task_type')['latency_to_task_server'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2fd81a-77ee-4ddb-85c0-1eeeb706f8fb",
   "metadata": {},
   "source": [
    "Parsl with Redis is _much_ better for the resolution times. Not that we should be too surprised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09402b9e-dbb4-423a-97b2-0b25ad5c716c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Measure Time to Decisions\n",
    "We have a few steps where the Thinker must quickly decide the next task.\n",
    "\n",
    "### Simulation Deployment\n",
    "We are going to measure the time in the log file between when a simulation finishes and the next is received by the task server.latency_result_sending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28e525-1d8a-4ebe-9537-a2087165e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simulation_decision_times(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Compute the time between when a simulation is received\n",
    "    and the next one sent off\n",
    "    \n",
    "    Args:\n",
    "        path: Path to run directory\n",
    "    Returns:\n",
    "        Dataframe with a 'to_task_server' and 'to_funcx' column\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the time a simulation was placed in the Redis queue\n",
    "    receive_times = pd.read_json(path / 'simulation-results.json', lines=True)['time_result_sent']\n",
    "    \n",
    "    # Get the times\n",
    "    to_task = []\n",
    "    to_funcx = []\n",
    "    with open(path / 'runtime.log') as fp:\n",
    "        for x in fp:\n",
    "            if 'Client sent a run_simulation ' in x:\n",
    "                to_task.append(datetime.strptime(x.split(\" - \")[0], \"%Y-%m-%d %H:%M:%S,%f\").timestamp())\n",
    "            elif 'Submitted run_simulation to run' in x:\n",
    "                to_funcx.append(datetime.strptime(x.split(\" - \")[0], \"%Y-%m-%d %H:%M:%S,%f\").timestamp())\n",
    "    \n",
    "    # Compute the reaction times\n",
    "    to_task = np.array(to_task)\n",
    "    to_funcx = np.array(to_funcx)\n",
    "    decision_times = [\n",
    "        np.min(to_task[to_task > x] - x) for x in receive_times[:len(to_task) // 10 * 8]\n",
    "    ]\n",
    "    funcx_times = [\n",
    "        np.min(to_funcx[to_funcx > x] - x) for x in receive_times[:len(to_task) // 10 * 8]\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'to_decision': decision_times,\n",
    "        'to_funcx': funcx_times\n",
    "    })\n",
    "funcx_sim_decision = get_simulation_decision_times(funcx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28de1a0-ce17-47af-acd4-047b7f90375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcx_sim_decision.describe([0.25, 0.50, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e320e447-1c63-44bf-8428-7d2b0c8f087d",
   "metadata": {},
   "source": [
    "### Training Response\n",
    "How long between trained model and the first evaluate_mpnn submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58df3d-72bc-43bc-bb6f-7e9355db72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_decision_times(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Compute the time between when a simulation is received\n",
    "    and the next one sent off\n",
    "    \n",
    "    Args:\n",
    "        path: Path to run directory\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the time the result was placed in the redis queue\n",
    "    receive_times = pd.read_json(path / 'training-results.json', lines=True)['time_result_sent']\n",
    "\n",
    "    # Get the times\n",
    "    done_times = []\n",
    "    to_process = []\n",
    "    to_task = []\n",
    "    to_funcx = []\n",
    "    with open(path / 'runtime.log') as fp:\n",
    "        for x in fp:\n",
    "            if 'left to go' in x: \n",
    "                to_process.append(datetime.strptime(x.split(\" - \")[0], \"%Y-%m-%d %H:%M:%S,%f\").timestamp())\n",
    "            elif 'Client sent a evaluate_mpnn ' in x:\n",
    "                to_task.append(datetime.strptime(x.split(\" - \")[0], \"%Y-%m-%d %H:%M:%S,%f\").timestamp())\n",
    "            elif 'Submitted evaluate_mpnn to run on ' in x:\n",
    "                to_funcx.append(datetime.strptime(x.split(\" - \")[0], \"%Y-%m-%d %H:%M:%S,%f\").timestamp())\n",
    "    \n",
    "    # Compute the reaction times\n",
    "    to_task = np.array(to_task)\n",
    "    to_funcx = np.array(to_funcx)\n",
    "    to_process = np.array(to_process)\n",
    "    resolve_times = [\n",
    "        np.min(to_process[to_process > x] - x) for x in receive_times\n",
    "    ]\n",
    "    decision_times = [\n",
    "        np.min(to_task[to_task > x] - x) for x in receive_times\n",
    "    ]\n",
    "    funcx_times = [\n",
    "        np.min(to_funcx[to_funcx > x] - x) for x in receive_times\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'to_resolve': resolve_times,\n",
    "        'to_inference': decision_times,\n",
    "        'to_funcx': funcx_times\n",
    "    })\n",
    "funcx_train_decision = get_training_decision_times(funcx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240405d-2bc3-4612-9f3f-932108dabef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcx_train_decision.describe([0.25, 0.50, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ac23db-696f-4b12-833d-724e65f28bc9",
   "metadata": {},
   "source": [
    "### Inference Decision\n",
    "Measure the time between when we get the last inference result and finish processing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1b7c2-19ac-4cd5-8b78-58fec97fea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_decision_times(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Compute the time between when a simulation is received\n",
    "    and the next one sent off\n",
    "    \n",
    "    Args:\n",
    "        path: Path to run directory\n",
    "    Returns:\n",
    "        Dataframe with a 'to_task_server' and 'to_funcx' column\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the time it was placed in queue\n",
    "    receive_times = pd.read_json(path / 'inference-results.json', lines=True)['time_result_sent'][95::96]\n",
    "\n",
    "    # Get the times\n",
    "    process_times = []\n",
    "    to_task = []\n",
    "    with open(path / 'runtime.log') as fp:\n",
    "        for x in fp:\n",
    "            if 'Processed inference task 96/96' in x:\n",
    "                process_times.append(datetime.strptime(x.split(\" - \")[0], \"%Y-%m-%d %H:%M:%S,%f\").timestamp())\n",
    "            elif 'Updated task list' in x:\n",
    "                to_task.append(datetime.strptime(x.split(\" - \")[0], \"%Y-%m-%d %H:%M:%S,%f\").timestamp())\n",
    "    # Compute the reaction times\n",
    "    to_task = np.array(to_task)\n",
    "    decision_times = np.subtract(to_task, process_times)\n",
    "    process_times = np.subtract(process_times, receive_times)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'to_process': process_times,\n",
    "        'to_update': decision_times,\n",
    "        'total': process_times + decision_times\n",
    "    })\n",
    "with (funcx / 'duplicates.json').open() as fp:\n",
    "    funcx_inf_decision = pd.concat([get_inference_decision_times(Path(x)) for x in json.load(fp)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e59d1-cacf-4637-9c33-af504359bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcx_inf_decision.describe([0.25, 0.50, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e678e47-69e6-4c37-8e17-b79686682f18",
   "metadata": {},
   "source": [
    "## Dispatch Time\n",
    "The final source of latency is the time it takes to dispatch compute onto a waiting worker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8f61c-5110-4c77-8e71-f17781a366b4",
   "metadata": {},
   "source": [
    "### Training Tasks\n",
    "Determine the time it takes for FuncX workers to start the training process. We know the nodes are empty at this point, so this latency is form of underutilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87365789-dc06-4c48-a8a8-e2db682796a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_training_startup(tasks: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Assess the latencies in starting up a model training\n",
    "    \n",
    "    Args:\n",
    "        tasks: List of tasks to be assessed\n",
    "    Returns:\n",
    "        Associated latencies\n",
    "    \"\"\"\n",
    "    \n",
    "    train_tasks = tasks.query('task_type==\"training\"').copy()\n",
    "    \n",
    "    # Compute the time a process is blocking while waiting for a proxy to resolve\n",
    "    def get_proxy_resolve_time(x):\n",
    "        \"\"\"Get \"\"\"\n",
    "        data = eval(x)\n",
    "        return sum([\n",
    "            i['resolve']['calls'] * i['resolve']['avg_time_ms'] / 1000 for i in data.values() if 'resolve' in i\n",
    "        ])\n",
    "    train_tasks['time_resolve'] = train_tasks['proxy_timing'].map(get_proxy_resolve_time)\n",
    "    train_tasks['total_serialization'] = (train_tasks.time_deserialize_inputs + train_tasks.time_serialize_inputs \n",
    "                                          + train_tasks.time_async_resolve_proxies)\n",
    "    train_tasks['funcx_communication'] = train_tasks['time_compute_started'] - train_tasks['time_input_received']\n",
    "    train_tasks['total_latency'] = (train_tasks['time_compute_started']  - train_tasks['time_created'] + train_tasks['time_resolve'])\n",
    "    \n",
    "    return train_tasks[['total_serialization', 'time_resolve', 'funcx_communication', 'total_latency', 'time_running']]\n",
    "funcx_train_startup = assess_training_startup(funcx_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93634680-8739-4ab7-9714-999b7a918dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcx_train_startup.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba40ba-0eaf-48ba-898c-10c35abea208",
   "metadata": {},
   "source": [
    "### Inference Tasks\n",
    "When the first model finishes training, there is under utilization between when the model finishes training and the results are sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee15a14-8909-4f2f-b3a6-5630a130f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_inference_initilization(tasks: pd.DataFrame, tasks_per_batch: int = 96) -> pd.DataFrame:\n",
    "    \"\"\"Assess the latencies in starting up a model training\n",
    "    \n",
    "    Args:\n",
    "        tasks: List of tasks to be assessed\n",
    "        tasks_per_batch: Number of tasks per inference batch\n",
    "    Returns:\n",
    "        Associated latencies\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the inference tasks\n",
    "    inf_tasks = tasks.query('task_type==\"inference\"').copy()\n",
    "    inf_tasks.sort_values('time_compute_started', inplace=True)\n",
    "    \n",
    "    # Assign them a batch ID\n",
    "    inf_tasks['batch_id'] = None\n",
    "    for gid, group in inf_tasks.groupby('run'):\n",
    "        n_batches = len(group) // tasks_per_batch + 1\n",
    "        batch_id = np.repeat(range(n_batches), tasks_per_batch)\n",
    "        inf_tasks.loc[group.index, 'batch_id'] = batch_id[:len(group)]\n",
    "    \n",
    "    # Remove the first batch\n",
    "    inf_tasks.query('batch_id > 0', inplace=True)\n",
    "    \n",
    "    # Get the first one to start for each batch\n",
    "    inf_tasks.sort_values('time_compute_started', inplace=True, ascending=True)\n",
    "    inf_tasks['total_serialization'] = inf_tasks.time_deserialize_inputs + inf_tasks.time_serialize_inputs + inf_tasks.time_async_resolve_proxies\n",
    "    inf_tasks['funcx_communication'] = inf_tasks['time_compute_started'] - inf_tasks['time_created']\n",
    "    inf_tasks['total_startup'] = inf_tasks['funcx_communication'] + inf_tasks['time_input_resolution']\n",
    "    \n",
    "    # Remove all but the columns we want \n",
    "    inf_tasks = inf_tasks[['run', 'batch_id', 'total_serialization', 'funcx_communication', 'time_input_resolution',\n",
    "                           'total_startup', 'time_running', 'proxy_timing']]\n",
    "    \n",
    "    # Get the first tasks\n",
    "    first_tasks = inf_tasks.drop_duplicates(['run', 'batch_id'], keep='first')\n",
    "    second_tasks = inf_tasks[np.logical_not(inf_tasks.index.map(lambda x: x in first_tasks.index).values)].drop_duplicates(['run', 'batch_id'], keep='first')\n",
    "    \n",
    "    return first_tasks, second_tasks\n",
    "funcx_inf_startup, funcx_inf_second = assess_inference_initilization(funcx_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97627e-9a5c-477f-89eb-87b631d9e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcx_inf_startup.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7eeae7-7348-4363-95c4-af38b35e027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcx_inf_second.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b32f91-192d-4640-af1d-8223033692a8",
   "metadata": {},
   "source": [
    "The time to start an inference task is limited by the model arriving at the worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ac503-4c32-40aa-aafb-47fa3d2004c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 2.5))\n",
    "\n",
    "stats = funcx_inf_startup.groupby('batch_id')['total_startup'].describe()\n",
    "ax.plot(stats.index, stats['mean'], '--o', label='Total startup')\n",
    "\n",
    "stats = funcx_inf_startup.groupby('batch_id')['time_input_resolution'].describe()\n",
    "ax.plot(stats.index, stats['mean'], '--s', label='Proxy resolution')\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Batch ID')\n",
    "ax.set_ylabel('Startup Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052677a-8849-4ab6-b403-2b8fd60c38f3",
   "metadata": {},
   "source": [
    "We can see that the time to start the first batch is much larger, where we have to send both the model and search space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb8506-c99c-4ae0-8bf2-651e4d8d836a",
   "metadata": {},
   "source": [
    "### Simulation Tasks\n",
    "The time between when a simulation task is created and placed on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13559a-6589-4529-9474-1414bc6a13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_tasks = funcx_tasks.query('task_type==\"simulation\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b16bc-b2bc-4619-a287-7c2303095d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sim_tasks.time_compute_started - sim_tasks.time_created).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c3f06-5658-475d-85cf-4937ef0a7e00",
   "metadata": {},
   "source": [
    "The median is only 330ms. There is a high maximum, but we are not getting charged for the job waiting in queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78acd8-8b43-4f27-a156-6c2e74f35790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
